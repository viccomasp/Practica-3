---
title: "Practica3"
author: "Marc Carbonés, Gerald Nilton, Victor Comas"
date: "2025-01-21"
output: html_document
---

# Librerías necesarias

```{r}
if (!require(readr)) install.packages("readr")
if (!require(stringr)) install.packages("stringr")
if (!require(dplyr)) install.packages("dplyr")
if (!require(tidyr)) install.packages("tidyr")
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(mltools)) install.packages("mltools")


```

# Exercici 1

```{r}
# Cargamos el data frame con los datos.
library(readr)
library(dplyr)

# Cargamos los datos en crudo:
datos_crudos <- read_table("epa-http.csv", col_names = FALSE)

# Con la siguiente variable vamos a hacer una limpieza de los datos:
datos <- datos_crudos

# Renombramos las columnas para que sea más inteligible
colnames(datos) <- c("fuente", "tiempo", "tipo", "url", "protocolo", "status", "bytes")


```

# Exercici 2

Aquí se muestra un resumen de los datos directamente extraídos del data frame (tan solo hemos cambiado el nombre de las columnas). Como no hemos hecho aún la limpieza de los datos (entre otras cosas categorizar bien las variables) no nos da información muy útil. Además figura algún dato sin sentido, como la media de la variable "status". Por eso una vez tengamos limpiados los datos vamos a volver a hacer un resumen.

```{r}
print(summary(datos))

```

# Exercici 3

```{r}
library(tidyr)

# Quitamos las comillas dobles que tienen dos de las columnas.
datos$tipo <- gsub('^"', '', datos$tipo)
datos$protocolo <- gsub('"$', '', datos$protocolo)

# Quitamos los claudátors que hay en la columna "tiempo".
datos$tiempo <- gsub('^\\[', '', datos$tiempo)
datos$tiempo <- gsub('\\]$', '', datos$tiempo)

# Montamos la columna tiempo en formato de datos elegantes.
# Primero separamos por tipo:
datos <- datos %>%
  separate(tiempo, into = c("dia", "hora", "minuto", "segundo"), sep = ":", convert = TRUE)

# Ahora, suponiendo que los días corresponden a enero de 2025, lo ponemos en formato elegante.
datos$fecha_hora <- as.POSIXct(
  paste("2025-01", datos$dia, datos$hora, datos$minuto, datos$segundo, sep = "-"),
  format = "%Y-%m-%d-%H-%M-%S"
)

# Eliminamos las columnas que nos sobran.
datos <- datos %>% select(-dia, -hora, -minuto, -segundo)

# Movemos la columna otra vez como segunda columna.
datos <- datos[, c("fuente", "fecha_hora", "tipo", "url", "protocolo", "status", "bytes")]

# Reclasificamos a factor las columnas "status", "tipo" y "protocolo", ya que tienen un número limitado de posibles categorías.
datos$status <- factor(datos$status)
datos$tipo <- factor(datos$tipo)
datos$protocolo <- factor(datos$protocolo)

# La columna bytes debería ser de tipo numérico:
datos$bytes <- as.numeric(datos$bytes)

# Ahora, una vez limpiados los datos, podemos hacer un resumen con más información.
summary(datos)

```

Vemos como nos desglosa las variables:

-   **tipo**: *GET* (46020 coincidencias), *HEAD* (106) y *POST* (1622)

-   **protocolo**: *HTTP/0.2* (1) y HTTP/1.0 (47747).

-   **status**: *200* (36712), *304* (5300), *302* (4506), *404* (611), *403* (272), *501* (272) y *otros* que serían el 500 y el 400. Lo podemos ver si hacemos el siguiente comando:

```{r}
count(datos, status)
```

Además nos desglosa la columna de las **fechas y horas**:

-   El *mínimo* "min" y el *máximo* "max".

-   El *primer, segundo y tercer cuartil*: "1st qu", "median" y "3rd qu" respectivamente.

-   La *media* de los valores "mean".

# Exercici 4

```{r}
# Identificamos el número de usuarios únicos que hayan hecho una petición al servidor pero segregándolos según el código de status de la misma. 

peticiones_unicas <- dplyr::count(datos, fuente, status)
View(peticiones_unicas)

```

Como vemos, se muestra un data frame contabilizando cuantas peticiones se han hecho por parte de cada usuario separado por el código de status. El 200 Representa que la petición ha sido exitosa y los otros que aparecen significa que ha habido algún tipo de error.

Si quisieramos mostrar la tabla anterior pero solo para las peticiones que han sido exitosas (código de status 200) podríamos hacer lo siguiente:

```{r}
# Ahora podemos agrupar según si la petición ha sido exitosa (código de status 200) o si no.
peticiones_unicas_status <- peticiones_unicas %>%
  filter(status %in% c("200")) %>%
  group_by(status)
View(peticiones_unicas_status)
```

# Exercici 5

```{r}
# Agrupamos de nuevo, pero ahora para ver la frecuencia de las distintas peticiones HTTP. En este caso tendremos solo 3: "GET", "POST" y "HEAD".
peticiones_http <- dplyr::count(datos, tipo)
peticiones_http

```

Vemos que hay 46020 peticiones por "GET", 106 por "HEAD", y 1622 por "POST".

Lo siguiente es hacer lo mismo pero filtrando previamente por peticiones correspondientes a recursos ofrecidos de tipo imagen. Estos tipos

```{r}
# El primer paso es dejar claro qué extensiones pueden ser de tipo imagen:
posibles_extensiones <- "\\.(jpg|jpeg|jfif|pjpeg|pjp|apng|png|svg|avif|gif|bmp|webp)$"

# Creamos una nueva columna que refleje si el recurso es de tipo imagen o no. 
datos$es_imagen <- grepl(posibles_extensiones, datos$url, ignore.case = TRUE)

# De la anterior columna creamos un nuevo data frame únicamente con las peticiones a recursos de tipo imagen.
datos_imagen <- datos[datos$es_imagen, ]

# Finalmente identificamos la frecuencia de cada tipo de petición HTTP pero ahora filtrado por recurso de tipo imagen.
peticiones_http_imagen <- dplyr::count(datos_imagen, tipo)
peticiones_http_imagen


```

# Exercici 6

```{r}
# Cargamos la librería ggplot2
library(ggplot2)
```

El primer gráfico que haremos será un **boxplot** de las **horas** de las peticiones. Este representará las cuartiles (entre ellos la mediana) y como están distribuidos.

```{r}
ggplot(datos, aes(x = fecha_hora)) +
  geom_boxplot(fill = "cornflowerblue", color = "blue3") +
  labs(
    title = "Boxplot de las peticiones por hora",
    x = "Hora"
  ) +
  scale_x_continuous(
    breaks = c(min(datos$fecha_hora), median(datos$fecha_hora), max(datos$fecha_hora))
  ) + 
  theme_minimal() + 
  theme(
    axis.text.y = element_blank(),   # Eliminar las etiquetas del eje Y
    axis.ticks.y = element_blank()   # Eliminar las marcas del eje Y
  )


```

Gracias a este gráfico podemos ver, por ejemplo, que en el primer 25% de los datos ha habido bastantes más peticiones que en el segundo y tercer 25% (e incluso que el último 25%) de los datos. También observamos que hay una pequeña diferencia de cantidad de peticiones en las peticiones que representan desde el segundo hasta el tercer cuartil. Finalmente observamos a la izquierda algunos valores atípicos extraídos del data frame.


A continuación haremos un "pie chart" con la frecuencia de los diferentes códigos de status de respuesta a las peticiones.
```{r}
que_status <- dplyr::count(datos, status)

que_status$status <- factor(que_status$status)

library(RColorBrewer)

ggplot(que_status, aes(x = "", y = n, fill= status)) + 
  geom_bar(stat = "identity") + 
  coord_polar("y") + 
  labs(title = "Porcentaje de status", fill = "Status code") + 
  scale_fill_brewer(palette = "Dark2") +
  theme_void()
```
Vemos representada la frecuencia con la que sale cada status code de las peticiones. Observamos como el más común es la respuesta con éxito del servidor (200). Pero no se aprecian muy bien los códigos de status que salen pocas veces, por tanto vamos a hacer un segundo pie chart con tan solo las respuesta no exitosas de modo que podamos ver mejor qué error ha salido.

```{r}
que_status_error <- que_status %>%
  dplyr::filter(status!=200)

ggplot(que_status_error, aes(x = "", y = n, fill= status)) + 
  geom_bar(stat = "identity") + 
  coord_polar("y") + 
  labs(title = "Porcentaje de status (no exitosos)", fill = "Status code") + 
  scale_fill_brewer(palette = "Paired") +
  theme_void()
```
Ahora si que apreciamos a simple vista todos los códigos de error que figuran en el data frame. Por ejemplo los errores 302 y 304 son los que más aparecen y el 400 y 500, los que menos.

# Exercici 7

```{r}
# Como ya tenemos la columna "fecha_hora" en formato POSIXct, solo nos queda generar el gráfico con ggplot2. El argumento binwidth es el intervalo de cada barra en segundos, en este caso 900 (15 minutos). 
ggplot(datos, aes(x = fecha_hora)) +
  geom_histogram(binwidth = 900, fill = "darkgrey", color = "black") +  
  labs(
    title = "Distribución de peticiones cada 15 minutos",
    x = "Tiempo (fecha y hora)",
    y = "Frecuencia de peticiones"
  ) +
  theme_minimal()
```
Notamos como el gráfico se asemeja a una distribución normal, con una gran cantidad de peticiones entre las 7 de la mañana y las 18h y un ritmo más calmado en los extremos.  
# Exercici 8

```{r}
# Librerías necesarias
library(mltools)
library(data.table)

# Creamos nuevo data frame con el que vamos hacer el aprendizaje no supervisado.
datos_one_hot <- one_hot(as.data.table(datos), sparsifyNAs = TRUE)

# Reemplazamos los NA de la columna "bytes" por 0 para hacer el análisis de clústering.
datos_one_hot$bytes[is.na(datos_one_hot$bytes)] <- 0

# Descartamos columnas no numéricas:
datos_one_hot$fuente <- NULL
datos_one_hot$fecha_hora <- NULL
datos_one_hot$url <- NULL
datos_one_hot$es_imagen <- NULL

# Desde aquí no sé como seguir
# Escalamos datos para normalizarlos
datos_escalados <- scale(datos_one_hot)

# Hacemos k-means para valores de k=3 y k=5.
kmeans_result_3 <- kmeans(datos_escalados, centers = 3, nstart = 25)
kmeans_result_5 <- kmeans(datos_escalados, centers = 5, nstart = 25)

datos_one_hot$cluster_3 <- as.factor(kmeans_result_3$cluster)
datos_one_hot$cluster_5 <- as.factor(kmeans_result_5$cluster)


# Calcular la varianza intra-clúster para diferentes valores de k
wss <- sapply(1:10, function(k) {
  kmeans(datos_escalados, centers = k, nstart = 25)$tot.withinss
})

```

# Exercici 9

```{r}

# Graficar la varianza intra-clúster
plot(1:10, wss,
     type = "b", pch = 19, frame = FALSE,
     xlab = "Número de clústeres (k)",
     ylab = "Varianza intra-clúster")


# Gráfico de dispersión para k=3
ggplot(datos_one_hot, aes(x = bytes, y = tipo_GET, color = cluster_3)) +
  geom_point() +
  labs(title = "Clustering con k=3")

# Gráfico de dispersión para k=5
ggplot(datos_one_hot, aes(x = bytes, y = tipo_GET, color = cluster_5)) +
  geom_point() +
  labs(title = "Clustering con k=5")

```
