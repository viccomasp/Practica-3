---
title: "Practica3"
author: "Marc Carbonès, Gerald Nilton, Victor Comas"
date: "2025-01-21"
output: html_document
---

# Librerías necesarias

```{r}
if (!require(readr)) install.packages("readr")
if (!require(stringr)) install.packages("stringr")
if (!require(dplyr)) install.packages("dplyr")
if (!require(tidyr)) install.packages("tidyr")

```

# Exercici 1

```{r}
# Cargamos el data frame con los datos.
library(readr)
library(dplyr)

# Cargamos los datos en crudo:
datos_crudos <- read_table("epa-http.csv", col_names = FALSE)

# Con la siguiente variable vamos a hacer una limpieza de los datos:
datos <- datos_crudos

# Renombramos las columnas para que sea más inteligible
colnames(datos) <- c("fuente", "tiempo", "tipo", "url", "protocolo", "status", "bytes")


```

# Exercici 2

```{r}
# Aquí se muestra un resumen de los datos directamente extraídos del data frame (tan solo hemos cambiado el nombre de las columnas). Como no hemos hecho aún la limpieza de los datos (entre otras cosas categorizar bien las variables) no nos da información muy útil. Además figura algún dato sin sentido, como la media de la variable "status". Por eso una vez tengamos limpiados los datos vamos a volver a hacer un resumen. 
summary(datos)

```

# Exercici 3

```{r}
library(tidyr)

# Quitamos las comillas dobles que tienen dos de las columnas.
datos$tipo <- gsub('^"', '', datos$tipo)
datos$protocolo <- gsub('"$', '', datos$protocolo)

# Quitamos los claudátors que hay en la columna "tiempo".
datos$tiempo <- gsub('^\\[', '', datos$tiempo)
datos$tiempo <- gsub('\\]$', '', datos$tiempo)

# Montamos la columna tiempo en formato de datos elegantes.
# Primero separamos por tipo:
datos <- datos %>%
  separate(tiempo, into = c("dia", "hora", "minuto", "segundo"), sep = ":", convert = TRUE)

# Ahora, suponiendo que los días corresponden a enero de 2025, lo ponemos en formato elegante.
datos$fecha_hora <- as.POSIXct(
  paste("2025-01", datos$dia, datos$hora, datos$minuto, datos$segundo, sep = "-"),
  format = "%Y-%m-%d-%H-%M-%S"
)

# Eliminamos las columnas que nos sobran.
datos <- datos %>% select(-dia, -hora, -minuto, -segundo)

# Movemos la columna otra vez como segunda columna.
datos <- datos[, c("fuente", "fecha_hora", "tipo", "url", "protocolo", "status", "bytes")]

# Categorizamos la columna como fecha. 
as.Date(datos$fecha_hora)

# Reclasificamos a factor las columnas "status", "tipo" y "protocolo", ya que tienen un número limitado de posibles categorías.
datos$status <- factor(datos$status)
datos$tipo <- factor(datos$tipo)
datos$protocolo <- factor(datos$protocolo)

# Ahora, una vez limpiados los datos, podemos hacer un resumen con más información.
summary(datos)

```

Vemos como nos desglosa las variables:

-   **tipo**: *GET* (46020 coincidencias), *HEAD* (106) y *POST* (1622)

-   **protocolo**: *HTTP/0.2* (1) y HTTP/1.0 (47747).

-   **status**: *200* (36712), *304* (5300), *302* (4506), *404* (611), *403* (272), *501* (272) y *otros* que serían el 500 y el 400. Lo podemos ver si hacemos el siguiente comando:
```{r}
count(datos, status)
```

Además nos desglosa la columna de las fechas y horas:
* El mínimo "min" y el máximo "max".
* El primer, segundo y tercer cuartil: "1st qu", "median" y "3rd qu" respectivamente.
* La media de los valores "mean".


# Exercici 4

```{r}
# Identificamos el número de usuarios únicos que hayan hecho una petición al servidor pero segregándolos según el código de status de la misma. 

peticiones_unicas <- dplyr::count(datos, fuente, status)

# Ahora podemos agrupar según si la petición ha sido exitosa (código de status 200) o si no.
peticiones_unicas_status <- peticiones_unicas %>%
  filter(status %in% c("200")) %>%
  group_by(status)

```

# Exercici 5

```{r}

```

# Exercici 6

```{r}

```

# Exercici 7

```{r}

```

# Exercici 8

```{r}

```

# Exercici 9

```{r}

```
