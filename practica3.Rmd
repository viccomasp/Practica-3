---
title: "Practica3"
author: "Marc Carbonès, Gerald Nilton, Victor Comas"
date: "2025-01-21"
output: html_document
---

# Librerías necesarias

```{r}
if (!require(readr)) install.packages("readr")
if (!require(stringr)) install.packages("stringr")
if (!require(dplyr)) install.packages("dplyr")
if (!require(tidyr)) install.packages("tidyr")
if (!require(ggplot2)) install.packages("ggplot2")

```

# Exercici 1

```{r}
# Cargamos el data frame con los datos.
library(readr)
library(dplyr)

# Cargamos los datos en crudo:
datos_crudos <- read_table("epa-http.csv", col_names = FALSE)

# Con la siguiente variable vamos a hacer una limpieza de los datos:
datos <- datos_crudos

# Renombramos las columnas para que sea más inteligible
colnames(datos) <- c("fuente", "tiempo", "tipo", "url", "protocolo", "status", "bytes")


```

# Exercici 2

Aquí se muestra un resumen de los datos directamente extraídos del data frame (tan solo hemos cambiado el nombre de las columnas). Como no hemos hecho aún la limpieza de los datos (entre otras cosas categorizar bien las variables) no nos da información muy útil. Además figura algún dato sin sentido, como la media de la variable "status". Por eso una vez tengamos limpiados los datos vamos a volver a hacer un resumen.

```{r}
print(summary(datos))

```

# Exercici 3

```{r}
library(tidyr)

# Quitamos las comillas dobles que tienen dos de las columnas.
datos$tipo <- gsub('^"', '', datos$tipo)
datos$protocolo <- gsub('"$', '', datos$protocolo)

# Quitamos los claudátors que hay en la columna "tiempo".
datos$tiempo <- gsub('^\\[', '', datos$tiempo)
datos$tiempo <- gsub('\\]$', '', datos$tiempo)

# Montamos la columna tiempo en formato de datos elegantes.
# Primero separamos por tipo:
datos <- datos %>%
  separate(tiempo, into = c("dia", "hora", "minuto", "segundo"), sep = ":", convert = TRUE)

# Ahora, suponiendo que los días corresponden a enero de 2025, lo ponemos en formato elegante.
datos$fecha_hora <- as.POSIXct(
  paste("2025-01", datos$dia, datos$hora, datos$minuto, datos$segundo, sep = "-"),
  format = "%Y-%m-%d-%H-%M-%S"
)

# Eliminamos las columnas que nos sobran.
datos <- datos %>% select(-dia, -hora, -minuto, -segundo)

# Movemos la columna otra vez como segunda columna.
datos <- datos[, c("fuente", "fecha_hora", "tipo", "url", "protocolo", "status", "bytes")]

# Categorizamos la columna como fecha. 
as.Date(datos$fecha_hora)

# Reclasificamos a factor las columnas "status", "tipo" y "protocolo", ya que tienen un número limitado de posibles categorías.
datos$status <- factor(datos$status)
datos$tipo <- factor(datos$tipo)
datos$protocolo <- factor(datos$protocolo)

# Ahora, una vez limpiados los datos, podemos hacer un resumen con más información.
summary(datos)

```

Vemos como nos desglosa las variables:

-   **tipo**: *GET* (46020 coincidencias), *HEAD* (106) y *POST* (1622)

-   **protocolo**: *HTTP/0.2* (1) y HTTP/1.0 (47747).

-   **status**: *200* (36712), *304* (5300), *302* (4506), *404* (611), *403* (272), *501* (272) y *otros* que serían el 500 y el 400. Lo podemos ver si hacemos el siguiente comando:

```{r}
count(datos, status)
```

Además nos desglosa la columna de las **fechas y horas**:

-   El *mínimo* "min" y el *máximo* "max".

-   El *primer, segundo y tercer cuartil*: "1st qu", "median" y "3rd qu" respectivamente.

-   La *media* de los valores "mean".

# Exercici 4

```{r}
# Identificamos el número de usuarios únicos que hayan hecho una petición al servidor pero segregándolos según el código de status de la misma. 

peticiones_unicas <- dplyr::count(datos, fuente, status)
View(peticiones_unicas)

```

Como vemos, se muestra un data frame contabilizando cuantas peticiones se han hecho por parte de cada usuario separado por el código de status. El 200 Representa que la petición ha sido exitosa y los otros que aparecen significa que ha habido algún tipo de error.

Si quisieramos mostrar la tabla anterior pero solo para las peticiones que han sido exitosas (código de status 200) podríamos hacer lo siguiente:

```{r}
# Ahora podemos agrupar según si la petición ha sido exitosa (código de status 200) o si no.
peticiones_unicas_status <- peticiones_unicas %>%
  filter(status %in% c("200")) %>%
  group_by(status)
View(peticiones_unicas_status)
```

# Exercici 5

```{r}
# Agrupamos de nuevo, pero ahora para ver la frecuencia de las distintas peticiones HTTP. En este caso tendremos solo 3: "GET", "POST" y "HEAD".
peticiones_http <- dplyr::count(datos, tipo)
peticiones_http

```

Vemos que hay 46020 peticiones por "GET", 106 por "HEAD", y 1622 por "POST".

Lo siguiente es hacer lo mismo pero filtrando previamente por peticiones correspondientes a recursos ofrecidos de tipo imagen. Estos tipos

```{r}
# El primer paso es dejar claro qué extensiones pueden ser de tipo imagen:
posibles_extensiones <- "\\.(jpg|jpeg|jfif|pjpeg|pjp|apng|png|svg|avif|gif|bmp|webp)$"

# Creamos una nueva columna que refleje si el recurso es de tipo imagen o no. 
datos$es_imagen <- grepl(posibles_extensiones, datos$url, ignore.case = TRUE)

# De la anterior columna creamos un nuevo data frame únicamente con las peticiones a recursos de tipo imagen.
datos_imagen <- datos[datos$es_imagen, ]

# Finalmente identificamos la frecuencia de cada tipo de petición HTTP pero ahora filtrado por recurso de tipo imagen.
peticiones_http_imagen <- dplyr::count(datos_imagen, tipo)
peticiones_http_imagen


```

# Exercici 6

```{r}
# Cargamos la librería ggplot2
library(ggplot2)
```

El primer gráfico que haremos será un **boxplot** de las **horas** de las peticiones. Este representará las cuartiles (entre ellos la mediana) y como están distribuidos.

```{r}
ggplot(datos, aes(x = fecha_hora)) +
  geom_boxplot(fill = "cornflowerblue", color = "blue3") +
  labs(
    title = "Boxplot de las peticiones por hora",
    x = "Hora"
  ) +
  scale_x_continuous(
    breaks = c(min(datos$fecha_hora), median(datos$fecha_hora), max(datos$fecha_hora))
  ) + 
  theme_minimal() + 
  theme(
    axis.text.y = element_blank(),   # Eliminar las etiquetas del eje Y
    axis.ticks.y = element_blank()   # Eliminar las marcas del eje Y
  )


```

Gracias a este gráfico podemos ver, por ejemplo, que en el primer 25% de los datos ha habido bastantes más peticiones que en el segundo y tercer 25% (e incluso que el último 25%) de los datos. También observamos que hay una pequeña diferencia de cantidad de peticiones en las peticiones que representan desde el segundo hasta el tercer cuartil. Finalmente observamos a la izquierda algunos valores atípicos extraídos del data frame.

# Exercici 7

```{r}

```

# Exercici 8

```{r}

```

# Exercici 9

```{r}

```
